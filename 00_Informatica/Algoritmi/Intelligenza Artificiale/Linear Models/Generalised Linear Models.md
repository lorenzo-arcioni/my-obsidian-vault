# Generalized Linear Models (GLMs)

I **Generalized Linear Models (GLMs)** sono una classe flessibile di modelli statistici che generalizzano la regressione lineare per target che seguono distribuzioni appartenenti alla famiglia esponenziale. Forniscono un framework unificato per trattare problemi con target continui, binari o discreti. I GLMs sono ampiamente utilizzati in vari campi, come l'econometria, la biostatistica e il machine learning, grazie alla loro capacità di adattarsi a diversi tipi di dati e di modellare relazioni complesse tra variabili.

## Componenti principali dei GLMs

Un GLM è definito da tre componenti principali: la **distribuzione dei target**, la **funzione di link** e la **funzione di varianza**. Questi componenti lavorano insieme per modellare la relazione tra le variabili indipendenti (input) e la variabile dipendente (target).

### 1. Distribuzione dei target

I target $y$ appartengono alla **famiglia esponenziale delle distribuzioni**, che è una classe di distribuzioni che può essere espressa nella forma:

$$
p(y|\theta, \phi) = \exp\left(\frac{y\theta - b(\theta)}{\phi} + c(y, \phi)\right)
$$

Dove:
- **$\theta$**: è il **parametro naturale**, una trasformazione del parametro della distribuzione che facilita la rappresentazione nella forma esponenziale. Questo parametro è legato alla media della distribuzione.
- **$b(\theta)$**: è la **funzione cumulativa logaritmica**, che determina la normalizzazione della distribuzione e la relazione tra $\theta$ e la media della distribuzione.
- **$\phi$**: è il **parametro di dispersione**, che controlla la variabilità dei dati intorno alla media. Questo parametro è rilevante per distribuzioni come la gamma e la normale, ma è fissato per distribuzioni come Bernoulli e Poisson.
- **$c(y, \phi)$**: è la **funzione di normalizzazione**, che garantisce che la distribuzione si integri a 1 e dipende dalla specifica distribuzione utilizzata.

**Esempi comuni di distribuzioni nella famiglia esponenziale**:
- **Normale**: $\theta = \mu$, $\phi = \sigma^2$.
- **Bernoulliana**: $\theta = \log\frac{\pi}{1-\pi}$.
- **Poissoniana**: $\theta = \log(\lambda)$.

### 2. Funzione di link

La **funzione di link** collega la media condizionale $\mu = \mathbb{E}[y|x]$ al **predictor lineare** $\eta$, che è una combinazione lineare delle variabili indipendenti:

$$
g(\mu) = \eta = \mathbf{w}^\top \mathbf{x} + b
$$

Dove:
- **$g(\cdot)$**: è la funzione di link, che trasforma la media $\mu$ in una scala lineare.
- **$\eta$**: è il **predictor lineare**, una combinazione lineare degli input $\mathbf{x}$ con pesi $\mathbf{w}$ e un termine di bias $b$.

**Esempi comuni di funzioni di link**:
- **Identità**: $g(\mu) = \mu$ (usata nella regressione lineare).
- **Logit**: $g(\mu) = \log\frac{\mu}{1-\mu}$ (usata nella regressione logistica).
- **Logaritmica**: $g(\mu) = \log(\mu)$ (usata nella regressione di Poisson).

### 3. Funzione di varianza

Nei GLMs, la varianza di $y$ è una funzione della media $\mu$:

$$
\text{Var}(y) = \phi v(\mu)
$$

Dove:
- **$v(\mu)$**: è la **funzione di varianza**, che dipende dalla specifica distribuzione utilizzata. Ad esempio, per la distribuzione normale, $v(\mu) = 1$, mentre per la distribuzione di Poisson, $v(\mu) = \mu$.

## Formulazione matematica

### 4. Probabilità condizionale

La probabilità condizionale di $y$ dato $\mathbf{x}$ e i parametri $\mathbf{w}$ è data da:

$$
p(y | \mathbf{x}, \mathbf{w}) = \exp\left(\frac{y\theta - b(\theta)}{\phi} + c(y, \phi)\right)
$$

Dove:
- **$\theta = g^{-1}(\eta)$**: è il parametro naturale, ottenuto applicando l'inversa della funzione di link al predictor lineare $\eta$.
- **$\eta = \mathbf{w}^\top \mathbf{x}$**: è il predictor lineare.

### 5. Stima dei parametri

La stima dei parametri $\mathbf{w}$ avviene massimizzando la **log-verosimiglianza**:

$$
\mathcal{L}(\mathbf{w}) = \sum_{i=1}^N \left( \frac{y_i \theta_i - b(\theta_i)}{\phi} + c(y_i, \phi) \right)
$$

Dove:
- **$\theta_i = g^{-1}(\mathbf{w}^\top \mathbf{x}_i)$**: è il parametro naturale per l'osservazione $i$-esima.
- **Metodi iterativi**: come il **reweighted least squares** o il **metodo di Newton-Raphson** sono utilizzati per massimizzare la log-verosimiglianza.

### 6. Predizione

Per un nuovo input $\mathbf{x}^*$, la predizione avviene in due passaggi:
1. Calcolo del predictor lineare:
   $$
   \eta^* = \mathbf{w}^\top \mathbf{x}^*
   $$
2. Applicazione della funzione di link inversa per ottenere la media predetta:
   $$
   \mu^* = g^{-1}(\eta^*)
   $$

## Esempi comuni di GLMs

### 7. [[Regressione Lineare]]

- **Distribuzione**: Normale.
- **Funzione di link**: Identità $g(\mu) = \mu$.
- **Modello**: $y = \mathbf{w}^\top \mathbf{x} + \epsilon$, con $\epsilon \sim \mathcal{N}(0, \sigma^2)$.

### 8. [[Regressione Logistica]]

- **Distribuzione**: Bernoulliana.
- **Funzione di link**: Logit $g(\mu) = \log\frac{\mu}{1-\mu}$.
- **Modello**: $\pi = \sigma(\mathbf{w}^\top \mathbf{x})$, dove $\sigma(\cdot)$ è la funzione sigmoide.

### 9. Regressione di Poisson

- **Distribuzione**: Poissoniana.
- **Funzione di link**: Logaritmica $g(\mu) = \log(\mu)$.
- **Modello**: $\lambda = \exp(\mathbf{w}^\top \mathbf{x})$.

## Proprietà dei GLMs

### 10. Flessibilità

I GLMs sono estremamente flessibili e possono modellare diversi tipi di dati scegliendo la distribuzione e una funzione di link appropriata. Ad esempio, possono essere utilizzati per dati continui, binari o di conteggio.

### 11. Proprietà analitiche

La linearità nei parametri consente una stima efficiente tramite metodi iterativi standard, come il metodo di Newton-Raphson o il reweighted least squares.

### 12. Limitazioni

- **Assunzione di indipendenza**: I GLMs assumono che i target siano indipendenti e distribuiti in modo identico (i.i.d.).
- **Scelta della distribuzione e della funzione di link**: Scelte errate possono compromettere le prestazioni del modello.

## Espansioni e variazioni

### 1. GLMMs (Generalized Linear Mixed Models)

I **GLMMs** sono un'estensione dei GLMs che include effetti randomici per modellare dati gerarchici o correlati. Sono particolarmente utili in contesti come studi longitudinali o dati con strutture gerarchiche.

### 2. Regolarizzazione

Tecniche di regolarizzazione come **Lasso**, **Ridge** o **Elastic Net** possono essere applicate ai GLMs per evitare overfitting e migliorare la generalizzazione del modello.

### 3. Modelli non lineari

I GLMs possono essere combinati con funzioni di base (ad esempio, polinomi o spline) per modellare relazioni non lineari tra le variabili indipendenti e il target.

## Conclusione

I **Generalized Linear Models (GLMs)** sono uno strumento potente e versatile per l'analisi statistica e il machine learning. Grazie alla loro flessibilità e alla capacità di adattarsi a diversi tipi di dati, i GLMs sono ampiamente utilizzati in molti campi applicativi. Tuttavia, è importante comprendere le loro assunzioni e limitazioni per utilizzarli in modo efficace.